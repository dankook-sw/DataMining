{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkFO0QTlG6M+39nkskM2/i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dankook-sw/DataMining/blob/main/project/HW_MNIST_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST 학습 실험\n",
        "\n",
        "수업 시간에 배웠던 손글씨 이미지 분류를 학습하는 실험입니다.\n",
        "\n",
        "실험의 목적은 하이퍼파라미터를 변경해 테스트 데이터에 대해 최대 정확도를 도출하는 것입니다.\n",
        "\n",
        "수정할 수 있는 부분은 다음과 같고 나머지 코드 부분은 수정이 불가합니다.\n",
        "1. 파일 경로\n",
        "2. 하이퍼 파라미터   \n",
        "*   iters_num\n",
        "*   batch_size\n",
        "*   learning_rate\n",
        "*   hidden_size\n",
        "\n",
        "3. accuracy 중간 확인 간격 (if i % 20 == 0:) 의 20. 중간 확인 간격이 짧으면 시간이 오래 걸릴 수 있으므로 조절하여도 됩니다.\n",
        "\n",
        "\n",
        "제출할 것\n",
        "1. 본인이 도출한 최대 정확도. jupyter notebook에 수행 결과가 출력된 대로 그대로 제출. (학번.ipynb)\n",
        "2. 학습 loss 그래프. train_loss_list를 이용해 iteration이 증가함에 따라 loss가 감소하는 양상을 matplotlib을 이용해 그래프로 그려 제출. (코드는 jupyter notebook에 남겨두고, 그래프 캡처하여 pdf 파일에 붙여넣기)\n",
        "3. 최대 정확도를 도출하기까지 하이퍼파라미터를 어떻게 변경해 보았고 그에 따른 결과가 어땠는지에 대한 분석을 반페이지 분량으로 작성하여 제출. (pdf 파일)"
      ],
      "metadata": {
        "id": "MhjscK2Olsxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFKlXy8O26zt"
      },
      "outputs": [],
      "source": [
        "#### 본인의 디렉터리 경로에 맞게 수정 가능 ######\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "#################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### 본인의 디렉터리 경로에 맞게 수정 가능 ######\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/MNIST')  # 구글 드라이브 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "from common.functions import sigmoid, softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient\n",
        "from keras.datasets import mnist\n",
        "#################################################"
      ],
      "metadata": {
        "id": "HvsMVYkr3Nvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### 수정 불가 ###################\n",
        "class TwoLayerNet:\n",
        "\n",
        "    # 초기화를 수행한다.\n",
        "    def __init__(self, input_size, hidden_size, output_size,\n",
        "                 weight_init_std=0.01):\n",
        "        # 가중치 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * \\\n",
        "            np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * \\\n",
        "            np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    # 예측(추론)을 수행한다.\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        return y\n",
        "\n",
        "    # 손실 함수의 값을 구한다.\n",
        "    # x : 입력데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return cross_entropy_error(y, t)\n",
        "\n",
        "    # 정확도를 구한다.\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    # 가중치 매개변수의 기울기를 구한다.\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads\n",
        "#################################################"
      ],
      "metadata": {
        "id": "XyAy1YrV3b3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "  ######### 데이터 로드 부분 수정 불가 ###########\n",
        "  (x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
        "  num_train_data = 10000\n",
        "  num_test_data = 1000\n",
        "  x_train = x_train[0:num_train_data]\n",
        "  t_train = t_train[0:num_train_data]\n",
        "  x_test = x_train[0:num_test_data]\n",
        "  t_test = t_train[0:num_test_data]\n",
        "  x_train = x_train.reshape(num_train_data, 784)\n",
        "  x_test = x_test.reshape(num_test_data, 784)\n",
        "  t_train = np.eye(10)[t_train]\n",
        "  t_test = np.eye(10)[t_test]\n",
        "  #################################################\n",
        "\n",
        "  ###### [수정할 부분] 하이퍼파라미터 설정#########\n",
        "  iters_num = 100\n",
        "  batch_size = 32\n",
        "  learning_rate = 0.05\n",
        "  hidden_size = 50\n",
        "  #################################################\n",
        "\n",
        "\n",
        "  ########### 학습 수행 부분 수정 불가 ############\n",
        "  # accuracy 중간 확인 간격은 수정 가능 (if i % 20 == 0:)\n",
        "\n",
        "  network = TwoLayerNet(input_size=784, hidden_size=hidden_size, output_size=10)\n",
        "\n",
        "  train_loss_list = []\n",
        "  train_acc_list = []\n",
        "  test_acc_list = []\n",
        "\n",
        "  # 1에폭당 반복 수\n",
        "  train_size = x_train.shape[0]\n",
        "  iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "  for i in range(iters_num):\n",
        "      # 미니배치 획득\n",
        "      batch_mask = np.random.choice(train_size, batch_size)\n",
        "      x_batch = x_train[batch_mask]\n",
        "      t_batch = t_train[batch_mask]\n",
        "\n",
        "      # 기울기 계산\n",
        "      grad = network.numerical_gradient(x_batch, t_batch)\n",
        "\n",
        "      # 매개변수 갱신\n",
        "      for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "          network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "      # 학습 loss 기록\n",
        "      loss = network.loss(x_batch, t_batch)\n",
        "      train_loss_list.append(loss)\n",
        "\n",
        "      # 테스트 loss 기록\n",
        "      print(\"iteration: \", i, \"     train loss \", loss)\n",
        "\n",
        "      # 정확도 계산\n",
        "      if i % 20 == 0:\n",
        "          train_acc = network.accuracy(x_train, t_train)\n",
        "          test_acc = network.accuracy(x_test, t_test)\n",
        "          train_acc_list.append(train_acc)\n",
        "          test_acc_list.append(test_acc)\n",
        "          print(\"train acc, test acc | \"\n",
        "                + str(train_acc) + \", \" + str(test_acc))\n",
        "  #################################################\n",
        "\n",
        "########## 최종 결과 출력 부분 수정 불가 ########\n",
        "test_acc = network.accuracy(x_test, t_test)\n",
        "print(\"final test accuracy: \", test_acc)\n",
        "#################################################"
      ],
      "metadata": {
        "id": "-0FgxQBAZxhj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}